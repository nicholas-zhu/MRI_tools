{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xczhu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "import sys\n",
    "sys.path.append(\"/home/xczhu/xzhu_clean/\")\n",
    "import MRI_tools.IO as IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "def load_imgs(img_dir):\n",
    "    Imgs = []\n",
    "    img_lst = os.listdir(img_dir)\n",
    "    img_lst.sort(reverse=True)\n",
    "    for filename in img_lst:\n",
    "        Imgs.append(np.array(Image.open(img_dir+filename)))\n",
    "        \n",
    "    return np.asarray(Imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling \n",
    "# 2.5 D sampling\n",
    "import random \n",
    "\n",
    "def CHAOS_sampling(data_dir, data_id, key = 'CT', nslice = 5):\n",
    "    full_data_dir = data_dir + '/' + key + '/' + str(data_id) \n",
    "    img = IO.read_dcm.read_dcms(full_data_dir + '/DICOM_anon/')\n",
    "    label = IO.image_io.load_imgs(full_data_dir + '/Ground/')\n",
    "\n",
    "    imgs, labels = sample_2p5(img, label, 100, nslice)\n",
    "    \n",
    "    return imgs, labels\n",
    "\n",
    "def sample_2p5(img_in, img_out, N_sample, nslice = 5):\n",
    "    N_sample = min([img_in.shape[0]-nslice, N_sample])\n",
    "    N = img_out.shape[0]\n",
    "    ind_list = [*range(nslice//2,N-nslice//2)]\n",
    "    random.shuffle(ind_list)\n",
    "    \n",
    "    imgs_in = []\n",
    "    imgs_out = []\n",
    "    for i in range(N_sample):\n",
    "        ind_t = ind_list[i]\n",
    "        imgs_in.append(img_in[ind_t-nslice//2:ind_t+(1+nslice)//2,...])\n",
    "        imgs_out.append(img_out[ind_t:ind_t+1,...])\n",
    "        \n",
    "    return imgs_in, imgs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Starting training:\n",
      "    Epochs: 20\n",
      "    Batch size: 20\n",
      "    Learning rate: 0.001\n",
      "    Checkpoints: True\n",
      "    CUDA: True\n",
      "\n",
      "Starting epoch 1/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.5712921023368835\n",
      "Epoch finished ! Loss: 0.4374381899833679\n",
      "Epoch finished ! Loss: 0.3878590166568756\n",
      "Epoch finished ! Loss: 0.35584962368011475\n",
      "Epoch finished ! Loss: 0.3377639651298523\n",
      "Epoch finished ! Loss: 0.32386112213134766\n",
      "Epoch finished ! Loss: 0.31387999653816223\n",
      "Epoch finished ! Loss: 0.30651533603668213\n",
      "Epoch finished ! Loss: 0.3015059232711792\n",
      "Epoch finished ! Loss: 0.2966545820236206\n",
      "Epoch finished ! Loss: 0.2925604581832886\n",
      "Epoch finished ! Loss: 0.2893160283565521\n",
      "Epoch finished ! Loss: 0.2863561511039734\n",
      "Epoch finished ! Loss: 0.2837763726711273\n",
      "Epoch finished ! Loss: 0.28157347440719604\n",
      "Epoch finished ! Loss: 0.27960363030433655\n",
      "Epoch finished ! Loss: 0.2779337763786316\n",
      "Epoch finished ! Loss: 0.27639099955558777\n",
      "Epoch finished ! Loss: 0.2751808166503906\n",
      "Epoch finished ! Loss: 0.27402108907699585\n",
      "Epoch finished ! Loss: 0.27287745475769043\n",
      "Starting epoch 2/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.500738263130188\n",
      "Epoch finished ! Loss: 0.3754177689552307\n",
      "Epoch finished ! Loss: 0.3336121141910553\n",
      "Epoch finished ! Loss: 0.31271126866340637\n",
      "Epoch finished ! Loss: 0.30025777220726013\n",
      "Epoch finished ! Loss: 0.29188427329063416\n",
      "Epoch finished ! Loss: 0.28593477606773376\n",
      "Epoch finished ! Loss: 0.28144338726997375\n",
      "Epoch finished ! Loss: 0.27795112133026123\n",
      "Epoch finished ! Loss: 0.2751561105251312\n",
      "Epoch finished ! Loss: 0.27300798892974854\n",
      "Epoch finished ! Loss: 0.27173349261283875\n",
      "Epoch finished ! Loss: 0.27006325125694275\n",
      "Epoch finished ! Loss: 0.26863041520118713\n",
      "Epoch finished ! Loss: 0.26739180088043213\n",
      "Epoch finished ! Loss: 0.26630744338035583\n",
      "Epoch finished ! Loss: 0.2653529644012451\n",
      "Epoch finished ! Loss: 0.2645018398761749\n",
      "Epoch finished ! Loss: 0.26373860239982605\n",
      "Epoch finished ! Loss: 0.2631143033504486\n",
      "Epoch finished ! Loss: 0.26254329085350037\n",
      "Starting epoch 3/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.5007107257843018\n",
      "Epoch finished ! Loss: 0.37535786628723145\n",
      "Epoch finished ! Loss: 0.3335723876953125\n",
      "Epoch finished ! Loss: 0.3127679228782654\n",
      "Epoch finished ! Loss: 0.3002689480781555\n",
      "Epoch finished ! Loss: 0.2918913662433624\n",
      "Epoch finished ! Loss: 0.28597140312194824\n",
      "Epoch finished ! Loss: 0.2814875543117523\n",
      "Epoch finished ! Loss: 0.27801039814949036\n",
      "Epoch finished ! Loss: 0.2752164602279663\n",
      "Epoch finished ! Loss: 0.27292442321777344\n",
      "Epoch finished ! Loss: 0.27101436257362366\n",
      "Epoch finished ! Loss: 0.26939794421195984\n",
      "Epoch finished ! Loss: 0.26801300048828125\n",
      "Epoch finished ! Loss: 0.2668429911136627\n",
      "Epoch finished ! Loss: 0.26579034328460693\n",
      "Epoch finished ! Loss: 0.26486167311668396\n",
      "Epoch finished ! Loss: 0.2644210457801819\n",
      "Epoch finished ! Loss: 0.26370111107826233\n",
      "Epoch finished ! Loss: 0.26301613450050354\n",
      "Epoch finished ! Loss: 0.2623963952064514\n",
      "Starting epoch 4/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.500007152557373\n",
      "Epoch finished ! Loss: 0.37531405687332153\n",
      "Epoch finished ! Loss: 0.33354291319847107\n",
      "Epoch finished ! Loss: 0.31265774369239807\n",
      "Epoch finished ! Loss: 0.3001263439655304\n",
      "Epoch finished ! Loss: 0.2917729914188385\n",
      "Epoch finished ! Loss: 0.2858317196369171\n",
      "Epoch finished ! Loss: 0.28139764070510864\n",
      "Epoch finished ! Loss: 0.2779090702533722\n",
      "Epoch finished ! Loss: 0.27512043714523315\n",
      "Epoch finished ! Loss: 0.2728375196456909\n",
      "Epoch finished ! Loss: 0.270934522151947\n",
      "Epoch finished ! Loss: 0.26932433247566223\n",
      "Epoch finished ! Loss: 0.2679707705974579\n",
      "Epoch finished ! Loss: 0.2668704390525818\n",
      "Epoch finished ! Loss: 0.2658217251300812\n",
      "Epoch finished ! Loss: 0.26494449377059937\n",
      "Epoch finished ! Loss: 0.26411426067352295\n",
      "Epoch finished ! Loss: 0.2633715867996216\n",
      "Epoch finished ! Loss: 0.2627033293247223\n",
      "Epoch finished ! Loss: 0.26211148500442505\n",
      "Starting epoch 5/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.5006427764892578\n",
      "Epoch finished ! Loss: 0.3753229081630707\n",
      "Epoch finished ! Loss: 0.3345315456390381\n",
      "Epoch finished ! Loss: 0.3133987784385681\n",
      "Epoch finished ! Loss: 0.30071955919265747\n",
      "Epoch finished ! Loss: 0.2922663986682892\n",
      "Epoch finished ! Loss: 0.2862285077571869\n",
      "Epoch finished ! Loss: 0.2817002534866333\n",
      "Epoch finished ! Loss: 0.27817803621292114\n",
      "Epoch finished ! Loss: 0.2753613591194153\n",
      "Epoch finished ! Loss: 0.27306845784187317\n",
      "Epoch finished ! Loss: 0.27115797996520996\n",
      "Epoch finished ! Loss: 0.2695304751396179\n",
      "Epoch finished ! Loss: 0.26813560724258423\n",
      "Epoch finished ! Loss: 0.266926646232605\n",
      "Epoch finished ! Loss: 0.2658746540546417\n",
      "Epoch finished ! Loss: 0.26494088768959045\n",
      "Epoch finished ! Loss: 0.26411083340644836\n",
      "Epoch finished ! Loss: 0.26337581872940063\n",
      "Epoch finished ! Loss: 0.2627097964286804\n",
      "Epoch finished ! Loss: 0.26211246848106384\n",
      "Starting epoch 6/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.5001736879348755\n",
      "Epoch finished ! Loss: 0.3751606047153473\n",
      "Epoch finished ! Loss: 0.3334404528141022\n",
      "Epoch finished ! Loss: 0.3125804662704468\n",
      "Epoch finished ! Loss: 0.30006444454193115\n",
      "Epoch finished ! Loss: 0.29172059893608093\n",
      "Epoch finished ! Loss: 0.28576064109802246\n",
      "Epoch finished ! Loss: 0.2812957167625427\n",
      "Epoch finished ! Loss: 0.27783164381980896\n",
      "Epoch finished ! Loss: 0.27504852414131165\n",
      "Epoch finished ! Loss: 0.2727714776992798\n",
      "Epoch finished ! Loss: 0.27087846398353577\n",
      "Epoch finished ! Loss: 0.2692781388759613\n",
      "Epoch finished ! Loss: 0.2679084539413452\n",
      "Epoch finished ! Loss: 0.26671457290649414\n",
      "Epoch finished ! Loss: 0.26567232608795166\n",
      "Epoch finished ! Loss: 0.264750599861145\n",
      "Epoch finished ! Loss: 0.2639358639717102\n",
      "Epoch finished ! Loss: 0.2632076144218445\n",
      "Epoch finished ! Loss: 0.2625473141670227\n",
      "Epoch finished ! Loss: 0.2619498670101166\n",
      "Starting epoch 7/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.500004768371582\n",
      "Epoch finished ! Loss: 0.375003457069397\n",
      "Epoch finished ! Loss: 0.33333590626716614\n",
      "Epoch finished ! Loss: 0.3125022351741791\n",
      "Epoch finished ! Loss: 0.30000191926956177\n",
      "Epoch finished ! Loss: 0.29166850447654724\n",
      "Epoch finished ! Loss: 0.2857159972190857\n",
      "Epoch finished ! Loss: 0.2812517285346985\n",
      "Epoch finished ! Loss: 0.27777937054634094\n",
      "Epoch finished ! Loss: 0.2750026285648346\n",
      "Epoch finished ! Loss: 0.2727504074573517\n",
      "Epoch finished ! Loss: 0.2708546221256256\n",
      "Epoch finished ! Loss: 0.26925045251846313\n",
      "Epoch finished ! Loss: 0.26787978410720825\n",
      "Epoch finished ! Loss: 0.26669755578041077\n",
      "Epoch finished ! Loss: 0.265654057264328\n",
      "Epoch finished ! Loss: 0.26473337411880493\n",
      "Epoch finished ! Loss: 0.26391690969467163\n",
      "Epoch finished ! Loss: 0.2631845772266388\n",
      "Epoch finished ! Loss: 0.262525349855423\n",
      "Epoch finished ! Loss: 0.2619289457798004\n",
      "Starting epoch 8/20.\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/5/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/14/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/1/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/2/DICOM_anon/\n",
      "Reading Dicom directory: /home/xczhu/tools/CHAOS/Train_Sets//CT/8/DICOM_anon/\n",
      "Epoch finished ! Loss: inf\n",
      "Epoch finished ! Loss: 0.5000036358833313\n",
      "Epoch finished ! Loss: 0.3750033378601074\n",
      "Epoch finished ! Loss: 0.3333360254764557\n",
      "Epoch finished ! Loss: 0.31251341104507446\n"
     ]
    }
   ],
   "source": [
    "from DL_torch import network\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "nslice = 5\n",
    "unet_level = 4\n",
    "net = network.UnetModule(nslice, 1, base_cn = 8, unet_level = unet_level)\n",
    "\n",
    "train_dir = '/home/xczhu/tools/CHAOS/Train_Sets/'\n",
    "train_id_lst = os.listdir('/home/xczhu/tools/CHAOS/Train_Sets/CT/')\n",
    "train_id_lst = train_id_lst[:5]\n",
    "\n",
    "test_dir = '/home/xczhu/tools/CHAOS/Test_Sets/'\n",
    "test_id = os.listdir('/home/xczhu/tools/CHAOS/Test_Sets/CT/')\n",
    "\n",
    "dir_checkpoint = './'\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "batch_size = 20\n",
    "n_channel = nslice\n",
    "\n",
    "gpu=torch.cuda.is_available()\n",
    "sig = nn.Sigmoid()\n",
    "save_cp=True\n",
    "print('''\n",
    "    Starting training:\n",
    "    Epochs: {}\n",
    "    Batch size: {}\n",
    "    Learning rate: {}\n",
    "    Checkpoints: {}\n",
    "    CUDA: {}\n",
    "'''.format(epochs, batch_size, lr, str(save_cp), str(gpu)))\n",
    "\n",
    "cp_prefix = 'Seg_channel{}_unet_level{}'.format(n_channel,unet_level)\n",
    "optimizer = optim.Adam(net.parameters(),lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if gpu:\n",
    "    device = torch.device(\"cpu\")\n",
    "    net = net.to(device)\n",
    "    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    i_imgs = []\n",
    "    o_imgs = []\n",
    "    for data_id in train_id_lst:\n",
    "        i_img, o_img = CHAOS_sampling(train_dir, data_id)\n",
    "        i_imgs = i_imgs + i_img\n",
    "        o_imgs = o_imgs + o_img\n",
    "    epoch_loss = 0\n",
    "    N_train = len(i_imgs)\n",
    "\n",
    "    for i in range(len(i_imgs)//batch_size):\n",
    "        i_img = np.array([i_imgs[k] for k in range(i*batch_size,min([(i+1)*batch_size,len(i_imgs)]))]).astype(np.float32)\n",
    "        o_img = np.array([o_imgs[k] for k in range(i*batch_size,min([(i+1)*batch_size,len(i_imgs)]))]).astype(np.float32)\n",
    "        i_img = torch.from_numpy(i_img)\n",
    "        o_img = torch.from_numpy(o_img)\n",
    "\n",
    "        if gpu:\n",
    "            i_img = i_img.to(device)\n",
    "            o_img = o_img.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        img_pred = net(i_img)\n",
    "        img_pred = sig(img_pred)\n",
    "        # img_mean = torch.mean(i_img.view(batch_size,-1,1,1,1),1,True)\n",
    "        img_pred = img_pred.view(-1)\n",
    "        o_img = o_img.view(-1)\n",
    "        #img_pred = img_pred.view(-1)\n",
    "        #o_img = o_img.view(-1)\n",
    "        loss = criterion(img_pred, o_img)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        # loss.item()\n",
    "        # print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, epoch_loss[0]))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "\n",
    "    if save_cp and (epoch+1)%10==0:\n",
    "        dir_checkpoint_cp = dir_checkpoint + cp_prefix +'CP{}.pth'.format(epoch + 1)\n",
    "        if os.path.exists(dir_checkpoint) is False:\n",
    "            os.mkdir(dir_checkpoint)\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "        }, dir_checkpoint_cp)\n",
    "        # torch.save(net.state_dict(),dir_checkpoint_cp)\n",
    "        print('Checkpoint {} saved !'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from super_resnet import *\n",
    "from util import *\n",
    "import os\n",
    "\n",
    "data_dir = '../tmp_data/'\n",
    "train_id = [1,2,3,4,5,6,7,8,9,10,11,13,14,15,16]\n",
    "test_id = [17,18,19,20]\n",
    "train_data_dir = [data_dir+'case{}/'.format(i) for i in train_id]\n",
    "test_data_dir = [data_dir+'case{}/'.format(i) for i in test_id]\n",
    "dir_checkpoint = './'\n",
    "\n",
    "def train(lr,epochs,batch_size,patch_size,n_channel,n_layers):\n",
    "    # prep step \n",
    "    net = super_resnet(n_channel,n_layers)\n",
    "    gpu=torch.cuda.is_available()\n",
    "    save_cp=True\n",
    "    patch_size = [patch_size,patch_size,patch_size]\n",
    "    print('''\n",
    "        Starting training:\n",
    "        Epochs: {}\n",
    "        Batch size: {}\n",
    "        Learning rate: {}\n",
    "        Checkpoints: {}\n",
    "        CUDA: {}\n",
    "    '''.format(epochs, batch_size, lr, str(save_cp), str(gpu)))\n",
    "    \n",
    "    cp_prefix = 'Sup_patch{}_layer{}_channel{}'.format(patch_size[0],n_layers,n_channel)\n",
    "    optimizer = optim.Adam(net.parameters(),lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    if gpu:\n",
    "        net = net.cuda()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "        net.train()\n",
    "        i_imgs, o_imgs = random_patch_sampler(train_data_dir, patch_size, 100)    \n",
    "        epoch_loss = 0\n",
    "        N_train = len(i_imgs)\n",
    "\n",
    "        for i in range(len(i_imgs)//batch_size):\n",
    "            i_img = np.array([[i_imgs[k]] for k in range(i*batch_size,min([(i+1)*batch_size,len(i_imgs)]))]).astype(np.float32)\n",
    "            o_img = np.array([[o_imgs[k]] for k in range(i*batch_size,min([(i+1)*batch_size,len(i_imgs)]))]).astype(np.float32)\n",
    "            i_img = torch.from_numpy(i_img)\n",
    "            o_img = torch.from_numpy(o_img)\n",
    "\n",
    "            if gpu:\n",
    "                i_img = i_img.cuda()\n",
    "                o_img = o_img.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            img_pred = net(i_img)\n",
    "            # img_mean = torch.mean(i_img.view(batch_size,-1,1,1,1),1,True)\n",
    "            img_pred = img_pred.view(-1)\n",
    "            o_img = o_img.view(-1)\n",
    "            #img_pred = img_pred.view(-1)\n",
    "            #o_img = o_img.view(-1)\n",
    "            loss = criterion(img_pred, o_img)\n",
    "            epoch_loss += loss\n",
    "\n",
    "            # loss.item()\n",
    "            # print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, epoch_loss[0]))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "\n",
    "        if save_cp and (epoch+1)%10==0:\n",
    "            dir_checkpoint_cp = dir_checkpoint + cp_prefix +'CP{}.pth'.format(epoch + 1)\n",
    "            if os.path.exists(dir_checkpoint) is False:\n",
    "                os.mkdir(dir_checkpoint)\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss\n",
    "            }, dir_checkpoint_cp)\n",
    "            # torch.save(net.state_dict(),dir_checkpoint_cp)\n",
    "            print('Checkpoint {} saved !'.format(epoch + 1))\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Training args\n",
    "    parser.add_argument('--learning_rate', '-lr', type=float, default=1e-3)\n",
    "    parser.add_argument('--epochs', '-n', type=int, default=50)\n",
    "    parser.add_argument('--batch_size', '-b', type=int, default=40)\n",
    "    # Neural network architecture args\n",
    "    parser.add_argument('--patch_size', '-p', type=int, default=64)\n",
    "    parser.add_argument('--n_layers', '-l', type=int, default=4)\n",
    "    parser.add_argument('--n_channel', '-c', type=int, default=16)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train(lr = args.learning_rate,\n",
    "          epochs = args.epochs,\n",
    "          batch_size = args.batch_size,\n",
    "          patch_size = args.patch_size,\n",
    "          n_channel = args.n_channel,\n",
    "          n_layers = args.n_layers)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 40\n",
    "plt.figure(1,figsize=(5,5))\n",
    "plt.imshow(img[N],cmap='gray')\n",
    "plt.imshow(label[N],cmap='jet', alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
